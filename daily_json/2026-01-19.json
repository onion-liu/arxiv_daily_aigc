[
    {
        "title": "EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation",
        "summary": "Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.",
        "url": "http://arxiv.org/abs/2601.12326v1",
        "published_date": "2026-01-18T09:20:09+00:00",
        "updated_date": "2026-01-18T09:20:09+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Jing Zhang",
            "Bingjie Fan"
        ],
        "tldr": "EmoKGEdit is a training-free image emotion editing framework leveraging a knowledge graph to disentangle emotional cues from content, improving emotion fidelity and structure preservation in generated images.",
        "tldr_zh": "EmoKGEdit是一个无需训练的图像情感编辑框架，它利用知识图谱来解耦情感线索和内容，从而提高生成图像中的情感保真度和结构保持。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 8,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "SDiT: Semantic Region-Adaptive for Diffusion Transformers",
        "summary": "Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.",
        "url": "http://arxiv.org/abs/2601.12283v1",
        "published_date": "2026-01-18T06:43:36+00:00",
        "updated_date": "2026-01-18T06:43:36+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Bowen Lin",
            "Fanjiang Ye",
            "Yihua Liu",
            "Zhenghui Guo",
            "Boyuan Zhang",
            "Weijian Zheng",
            "Yufan Xu",
            "Tiancheng Xing",
            "Yuke Wang",
            "Chengming Zhang"
        ],
        "tldr": "The paper introduces SDiT, a method to accelerate diffusion transformers for text-to-image synthesis by allocating computation adaptively based on semantic region complexity, achieving up to 3x speedup without significant quality loss.",
        "tldr_zh": "该论文介绍了SDiT，一种加速文本到图像合成扩散Transformer的方法，通过基于语义区域复杂性自适应地分配计算资源，实现高达3倍的加速，同时不会显著降低质量。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]