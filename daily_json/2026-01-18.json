[
    {
        "title": "UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation",
        "summary": "Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.",
        "url": "http://arxiv.org/abs/2601.11522v1",
        "published_date": "2026-01-16T18:59:58+00:00",
        "updated_date": "2026-01-16T18:59:58+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Ruiheng Zhang",
            "Jingfeng Yao",
            "Huangxuan Zhao",
            "Hao Yan",
            "Xiao He",
            "Lei Chen",
            "Zhou Wei",
            "Yong Luo",
            "Zengmao Wang",
            "Lefei Zhang",
            "Dacheng Tao",
            "Bo Du"
        ],
        "tldr": "The paper introduces UniX, a unified medical foundation model for chest X-ray understanding and generation, decoupling the tasks into autoregressive and diffusion branches, significantly improving performance with fewer parameters than existing methods.",
        "tldr_zh": "本文介绍 UniX，一种用于胸部 X 光片理解和生成的一体化医疗基础模型，将任务解耦为自回归和扩散分支，与现有方法相比，在参数更少的情况下显著提高了性能。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "ShapeR: Robust Conditional 3D Shape Generation from Casual Captures",
        "summary": "Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art.",
        "url": "http://arxiv.org/abs/2601.11514v1",
        "published_date": "2026-01-16T18:51:24+00:00",
        "updated_date": "2026-01-16T18:51:24+00:00",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Yawar Siddiqui",
            "Duncan Frost",
            "Samir Aroudj",
            "Armen Avetisyan",
            "Henry Howard-Jenkins",
            "Daniel DeTone",
            "Pierre Moulon",
            "Qirui Wu",
            "Zhengqin Li",
            "Julian Straub",
            "Richard Newcombe",
            "Jakob Engel"
        ],
        "tldr": "ShapeR proposes a novel approach for generating high-fidelity 3D shapes from casually captured image sequences by leveraging SLAM, 3D detection, and vision-language models, demonstrating significant improvements over existing methods in real-world scenarios.",
        "tldr_zh": "ShapeR 提出了一种新颖的方法，通过利用 SLAM、3D 检测和视觉语言模型，从随意捕获的图像序列中生成高保真 3D 形状，并在实际场景中展示了相对于现有方法的显著改进。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]