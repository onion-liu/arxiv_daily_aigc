[
    {
        "title": "TokensGen: Harnessing Condensed Tokens for Long Video Generation",
        "summary": "Generating consistent long videos is a complex challenge: while\ndiffusion-based generative models generate visually impressive short clips,\nextending them to longer durations often leads to memory bottlenecks and\nlong-term inconsistency. In this paper, we propose TokensGen, a novel two-stage\nframework that leverages condensed tokens to address these issues. Our method\ndecomposes long video generation into three core tasks: (1) inner-clip semantic\ncontrol, (2) long-term consistency control, and (3) inter-clip smooth\ntransition. First, we train To2V (Token-to-Video), a short video diffusion\nmodel guided by text and video tokens, with a Video Tokenizer that condenses\nshort clips into semantically rich tokens. Second, we introduce T2To\n(Text-to-Token), a video token diffusion transformer that generates all tokens\nat once, ensuring global consistency across clips. Finally, during inference,\nan adaptive FIFO-Diffusion strategy seamlessly connects adjacent clips,\nreducing boundary artifacts and enhancing smooth transitions. Experimental\nresults demonstrate that our approach significantly enhances long-term temporal\nand content coherence without incurring prohibitive computational overhead. By\nleveraging condensed tokens and pre-trained short video models, our method\nprovides a scalable, modular solution for long video generation, opening new\npossibilities for storytelling, cinematic production, and immersive\nsimulations. Please see our project page at\nhttps://vicky0522.github.io/tokensgen-webpage/ .",
        "url": "http://arxiv.org/abs/2507.15728v1",
        "published_date": "2025-07-21T15:37:33+00:00",
        "updated_date": "2025-07-21T15:37:33+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Wenqi Ouyang",
            "Zeqi Xiao",
            "Danni Yang",
            "Yifan Zhou",
            "Shuai Yang",
            "Lei Yang",
            "Jianlou Si",
            "Xingang Pan"
        ],
        "tldr": "TokensGen is a two-stage framework for generating consistent long videos using condensed tokens, addressing memory bottlenecks and inconsistencies common in existing methods.",
        "tldr_zh": "TokensGen是一个两阶段框架，它使用压缩的tokens来生成一致的长视频，解决了现有方法中常见的内存瓶颈和不一致问题。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 8,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]