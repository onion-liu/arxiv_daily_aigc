[
    {
        "title": "EvDiff: High Quality Video with an Event Camera",
        "summary": "As neuromorphic sensors, event cameras asynchronously record changes in brightness as streams of sparse events with the advantages of high temporal resolution and high dynamic range. Reconstructing intensity images from events is a highly ill-posed task due to the inherent ambiguity of absolute brightness. Early methods generally follow an end-to-end regression paradigm, directly mapping events to intensity frames in a deterministic manner. While effective to some extent, these approaches often yield perceptually inferior results and struggle to scale up in model capacity and training data. In this work, we propose EvDiff, an event-based diffusion model that follows a surrogate training framework to produce high-quality videos. To reduce the heavy computational cost of high-frame-rate video generation, we design an event-based diffusion model that performs only a single forward diffusion step, equipped with a temporally consistent EvEncoder. Furthermore, our novel Surrogate Training Framework eliminates the dependence on paired event-image datasets, allowing the model to leverage large-scale image datasets for higher capacity. The proposed EvDiff is capable of generating high-quality colorful videos solely from monochromatic event streams. Experiments on real-world datasets demonstrate that our method strikes a sweet spot between fidelity and realism, outperforming existing approaches on both pixel-level and perceptual metrics.",
        "url": "http://arxiv.org/abs/2511.17492v1",
        "published_date": "2025-11-21T18:49:18+00:00",
        "updated_date": "2025-11-21T18:49:18+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Weilun Li",
            "Lei Sun",
            "Ruixi Gao",
            "Qi Jiang",
            "Yuqin Ma",
            "Kaiwei Wang",
            "Ming-Hsuan Yang",
            "Luc Van Gool",
            "Danda Pani Paudel"
        ],
        "tldr": "The paper introduces EvDiff, an event-based diffusion model for generating high-quality videos from event camera data, using a surrogate training framework to leverage large-scale image datasets without paired event-image data.",
        "tldr_zh": "该论文介绍了EvDiff，一种基于事件的扩散模型，用于从事件相机数据生成高质量视频，使用替代训练框架来利用大型图像数据集，而无需配对的事件-图像数据。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]